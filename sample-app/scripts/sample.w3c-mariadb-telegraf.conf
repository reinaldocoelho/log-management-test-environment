# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  logtarget = "stderr"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            INPUT PLUGINS                                   #
###############################################################################

[[inputs.tail]]
  ## Log files to parse.
  ## These accept standard unix glob matching rules, but with the addition of
  ## ** as a "super asterisk". ie:
  ## /var/log/**.log ->recursively find all .log files in /var/log
  ## /var/log/*/*.log ->find all .log files with a parent dir in /var/log
  ## /var/log/apache.log -> only tail the apache log file
  files = ["/app/logs/*.txt"]
  from_beginning = true
  #name of the "Metric" (which I want to see in Grafana eventually)
  name_override = "w3c_log"
  watch_method = "poll"
  ## Custom patterns can also be defined here. Put one pattern per line.
  ## To test Grok Pattern: https://grokconstructor.appspot.com/do/match#result
  grok_patterns = ["%{TIMESTAMP_ISO8601:log_date} %{NOTSPACE:server_name} (%{IPV4:server_ipv4}|%{IPV6:server_ipv6}|%{IPV6:server_ipv6}:%{IPV4:server_ipv4}) %{WORD:http_method} %{NOTSPACE:uri_path} %{NOTSPACE:uri_query} %{NUMBER:server_port} (%{IPV4:user_ipv4}|%{IPV6:user_ipv6}|%{IPV6:user_ipv6}:%{IPV4:user_ipv4}) %{NOTSPACE:referer} %{NOTSPACE:host_uri} %{NUMBER:http_status} %{NUMBER:time_taken}"]
  data_format = "grok"

[[inputs.logparser]]
  ## Log files to parse.
  ## These accept standard unix glob matching rules, but with the addition of
  ## ** as a "super asterisk". ie:
  ## /var/log/**.log ->recursively find all .log files in /var/log
  ## /var/log/*/*.log ->find all .log files with a parent dir in /var/log
  ## /var/log/apache.log -> only tail the apache log file
  files = ["/app/logs/*.txt"]
  from_beginning = true
  #name of the "Metric" (which I want to see in Grafana eventually)
  measurement = "w3c_log"
  watch_method = "poll"
  ## Custom patterns can also be defined here. Put one pattern per line.
  ## To test Grok Pattern: https://grokconstructor.appspot.com/do/match#result
  grok_patterns = ["%{TIMESTAMP_ISO8601:log_date} %{NOTSPACE:server_name} (%{IPV4:server_ipv4}|%{IPV6:server_ipv6}|%{IPV6:server_ipv6}:%{IPV4:server_ipv4}) %{WORD:http_method} %{NOTSPACE:uri_path} %{NOTSPACE:uri_query} %{NUMBER:server_port} (%{IPV4:user_ipv4}|%{IPV6:user_ipv6}|%{IPV6:user_ipv6}:%{IPV4:user_ipv4}) %{NOTSPACE:referer} %{NOTSPACE:host_uri} %{NUMBER:http_status} %{NUMBER:time_taken}"]
  data_format = "grok"

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Output result to stdout for tests.
[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  files = ["stdout"]

# # Send metrics to SQL Database
[[outputs.sql]]
  ## Database driver
  ## Valid options: mssql (Microsoft SQL Server), mysql (MySQL), pgx (Postgres),
  ##  sqlite (SQLite3), snowflake (snowflake.com)
  driver = "mysql"

  ## Data source name
  ## The format of the data source name is different for each database driver.
  ## See the plugin readme for details.
  ## MariaDB DataSource format = username:password@protocol(address)/dbname?param=value (More: https://github.com/go-sql-driver/mysql#dsn-data-source-name)
  ## About MariaDB sql_mode: https://mariadb.com/kb/en/sql-mode/
  data_source_name = "sample:pass#word@tcp(mariadb:3306)/sampleapp?sql_mode=%27STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,ANSI_QUOTES%27"
 